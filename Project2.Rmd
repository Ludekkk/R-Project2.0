---
title: "Projekt 2.0"
author: "Michał Baran"
date: "20 maja 2019"
output: html_document
---

```{r, message=FALSE, results='hide', echo=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(tseries)
```

### Wprowadzenie
Celem projektu jest stworzenie funkcji symulującej próbki z rozkładów mieszanych oraz analiza mocy testów zgodności oraz rangowych dla próbek otrzymanych w ten sposób. Analiza będzie polegać na stworzeniu ramek danych uwzględniających moce testów w zależności od:  
* Długości próby.  
* Prawdopodobieństwa wylosowania liczby z pierwszego rozkładu.  
* Parametrów poszczególnych rozkładów.  

***

Do wykonania projektu posłużę się trzema testami:

- __Jarque Bera__  
Test ten jest najczęściej uzywanym testem w ekonometrii.Powodem tego jest jego prostota oraz znana nieskomplikowana postać rozkładu asymptotycznego. Konstrukcja statystyki testowej bazuje na wartościach momentów rozkłądu zmiennej losowej obliczonych na podstawie próby empiryczniej i porównaniu ich z momentami teoretycznumi rozkładu normalnego. Test weryfikuje hipotezę o jednowymiarowej normalności zmiennej losowej przeciwko innemu dowolnemu rozkładowi.

- __Shapiro-Wilka__  
Test ten jest uznawany za najlepszy do sprawdzania normalności rozkładu zmiennej losowej, ponieważ charakteryzuje go duża moc, czyli duże prawdopodobieństwo odrzucenia hipotezy zerowej jeśli jest ona fałszywa. Polecany jest dla małych próbek, ponieważ gdy liczba obserwacji przekracza 2000 może zwracać blędne wyniki. Test weryfikuje hipotezę mówiącą o o tym, że rozkład naszej zmiennej jest zbliżony do normalnego.  

- __Wilcoxona__  
Jest nieparametryczną alternatywą dla testu t-Studenta dla przypadku dwóch równolicznych próbek dających sis połączyć w pary. Często używa się tego testu do porównywania danych zebranych przed i po eksperymencie, w celu zbadania, czy nastąpiła istotna statystycznie zmiana.  

***
Dane którymi będę się posługiwał przedstawię w postaci wektorów.  

1. *p* - prawdopodobieństwo wylosowania liczby z pierwszego rozkładu 
2. *n* - długości próby  
3. *par1* - parametry pierwszego rozkładu  
4. *par2* - parametry drugiego rozkładu  

***

###Zadanie 1  
Podstawą całego projektu będzie stworzenie funkcji __rmix__, która pozwoli mi na symulowanie próbek z rozkładów mieszanych. Jej parametrami będą:  
-- __n__ - długość próby  
-- __family_1__ - pierwszy typ rozkładu  
-- __par_1__ - parametry pierwszego rozkładu  
-- __family_2__ - drugi typ rozkładu  
-- __par_2__ - parametry drugiego rozkładu  
-- __p__ - prawdopodobieństwo, że liczba pochodzi z pierwszego rozkładu  

***

Funkcja w oparciu o wektor __prob__, który jest wektorem posiadającym jedynie liczby *1* oraz *2* bada ile należy wylosować liczb z każdego z rozkładów. Następnie tworzy dwie próbki, które są wartościami pochodzącymi z wybranych przez nas rozkladów. Na końcu funkcja zwraca wektor, który jest połaczeniem obu tych próbek.  
```{r}
rmix <- function(n,family_1,par_1,family_2,par_2,p){
  
  prob <- sample(c(1,2), n, prob = c(p, 1-p), replace = T)
  
  sample1 <- eval(
    parse( text = 
             paste0("r", family_1, "(length(which(prob == 1)), ", 
                    paste(par_1, collapse = ", "),
                    ")"))
  )
  sample2 <- eval(
    parse( text = 
             paste0("r", family_2, "(length(which(prob == 2)), ", 
                    paste(par_2, collapse = ","),
                    ")"))
  )
  c(sample1,sample2)
}
```

###Zadanie 2  
Dzięki pomocy funkcji __rmix__ przeanalizuje moce testów zgodności dla mieszanki dwóch rozkładów normalnych przy hipotezie zerowej o rozkładzie normalnym.  

***

Najpierw zbadam czy zmiana wartości *n* oraz *p* istotnie wpływa na zmianę mocy testu.  
Poniższa analiza powinna sprawdzić czy poniższe hipotezy są prawdziwe:  

___Długość próby___  
H0: Wzrost długości próby powoduje wzrost mocy testu  
H1: Wzrost długości próby powoduje spadek mocy testu  

___Poziom prawdopodobieństwa wystąpienia zmiennych z pierwszego rozkładu___  
H0: Wzrost prawdopodobieństwa powoduje wzrost mocy testu  
H1: Wzrost prawdopodobieństwa powoduje spadek mocy testu  

Oczekiwanym rezultatem jest brak podstaw do odrzucenia hipotezy zerowej.  

***

Wprowadzam wartości poszczególnych zmiennych:
```{r}
#długość
n <- c(10,50,100,200)
#prawdopodobieństwo
p <- c(0.1,0.3,0.5,0.9)
#par_1
par1 <- c(5,4)
#par_2
par2 <- c(10,5)
#ilość symulacji
N <- 100
#alpha, która pozwala na badanie mocy testów
alpha <- 0.1
#testy - skrótowe nazy testów którymi posługuję się w projekcie
testy <- c("SW","JB")
```

Tworzę ramke danych:
```{r}
data1 <- expand.grid(n,p,testy)
colnames(data1) <- c("Dlugosc", "Prawdopodobienstwo","Test")

```

Dla każdej kombinacji z *data1* badam moc testów i zapisuje do wektora *powers*, który następnie dopisuje do ramki danych.
```{r}
set.seed(20)

powers <- sapply(1:nrow(data1),
                 function(i){
                   n <- data1[i, 1]
                   p <- data1[i, 2]
                   test <- data1[i, 3]
                   
                   p_vector <- sapply(rep(n, N), function(x){
                     sample <- rmix(n, "norm", par1, "norm", par2, p)
                     
                     if (test == "SW"){
                       result <- shapiro.test(sample)$p.value
                     } else if (test == "JB"){
                       result <- jarque.bera.test(sample)$p.value
                     }   
                     result
                   })
                   mean(p_vector < alpha)
                 })

data2 <- bind_cols(data1, Moc = powers)
```

Tworzę wykres przedstawiający jak zmienia się moc testów w zależności od *n* i *p*:
```{r, warning= FALSE, echo=FALSE, message=FALSE}
ggplot(data2,aes(x = Dlugosc, y = Moc, color = Test)) +
  labs(x = "Długość próby", y = "Moc") +
  geom_smooth() + 
  facet_wrap(~ Prawdopodobienstwo, nrow = 3)
```

Jak można wnioskować z powyższej grafiki, w obu badanych przypadkach nie mamy podstaw do odrzucenia hipotezy zerowej. Oznacza to, że wraz ze wzrostem długości próby oraz prawdopodobieństwa wylosowanie liczby z pierwszego rozkładu moc testu również wzrasta.   

***

Następnym punktem, będzie zbadanie jak zmiana parametrów pierwszego rozkładu wpłynie na moc testów. 
Aby to uczynić, tworzę nową ramkę danych dzięki której będę w stanie zmieniać pierwszy i drugi parametr w *par_1*.

```{r}
#długość
n <- c(10,50,100,200)
#prawdopodobieństwo
p <- 0.6
#par_2
par2 <- c(6,2)
#dane do zmiany
zmiana <- seq(2,10, by = .25)


data3 <- expand.grid(Dlugosc = n, Prawdo = p, Zmiana = zmiana, Test = testy)
```

Przy wykorzystaniu tej samej metodyki co wcześniej, wykonuję badanie mocy testów oraz wizualiazcję.
```{r, echo=FALSE, message=FALSE}
set.seed(20)

powers <- sapply(1:nrow(data3),
                 function(i){
                   n <- data3[i, 1]
                   par1 <- data3[i, 3]  
                   test <- data3[i, 4]
                   
                   p_vector <- sapply(rep(n, N), function(x){
                     sample <- rmix(n, "norm", c(par1,1), "norm", par2, p)
                     
                     if (test == "SW"){
                       result <- shapiro.test(sample)$p.value
                     } else if (test == "JB"){
                       result <- jarque.bera.test(sample)$p.value
                     }   
                     result
                   })
                   mean(p_vector < alpha)
                 })

data4 <- bind_cols(data3, Moc = powers)

  ggplot(data4,aes(x = Zmiana, y = Moc, color = Test)) +
  labs(title = "Zmiena mocy w zależności od par_1[1]", x = "Wartosc par1[1]", y = "Moc") +
  geom_smooth() + 
  facet_wrap(~ Dlugosc, nrow = 3)
```

```{r, echo=FALSE, message=FALSE}
set.seed(20)

powers <- sapply(1:nrow(data3),
                 function(i){
                   n <- data3[i, 1]
                   par1 <- data3[i, 3]  
                   test <- data3[i, 4]
                   
                   p_vector <- sapply(rep(n, N), function(x){
                     sample <- rmix(n, "norm", c(1,par1), "norm", par2, p)
                     
                     if (test == "SW"){
                       result <- shapiro.test(sample)$p.value
                     } else if (test == "JB"){
                       result <- jarque.bera.test(sample)$p.value
                     }   
                     result
                   })
                   mean(p_vector < alpha)
                 })

data4 <- bind_cols(data3, Moc = powers)


  ggplot(data4,aes(x = Zmiana, y = Moc, color = Test)) +
  labs(title = "Zmiena mocy w zależności od par_1[2]", x = "Wartosc par1[2]", y = "Moc") +
  geom_smooth() + 
  facet_wrap(~ Dlugosc, nrow = 3)
```

Jak widać na powyższych grafikach, moc testów maleje tylko w miejscu, gdzie parametry badanego przez nas rozkładu zbliżają się do wartości parametrów rozkładu drugiego. Spowodowane jest to faktem, że badane przez nas rozkłady w takiej syuacji nie różnią się od siebie znacząco.  

***
Ostatnim punktem będzie sprawdzenie czy zmiana parametrów drugiego rozkładu wpłynie istotnie na zmianę mocy testów.
Postępnowanie, które wykonam będzie identyczne jak w punkcie powyżej.   
  
Oto otrzymane wyniki:

```{r, echo=FALSE, message=FALSE}
#długość
n <- c(10,50,100,200)
#prawdopodobieństwo
p <- 0.6
#par_2
par1 <- c(6,2)
#dane do zmiany
zmiana <- seq(2,10, by = .25)

data3 <- expand.grid(Dlugosc = n, Prawdo = p, Zmiana = zmiana, Test = testy)
```

```{r, echo=FALSE, message=FALSE}
set.seed(20)
powers <- sapply(1:nrow(data3),
                 function(i){
                   n <- data3[i, 1]
                   par2 <- data3[i, 3]  
                   test <- data3[i, 4]
                   
                   p_vector <- sapply(rep(n, N), function(x){
                     sample <- rmix(n, "norm", par1, "norm", c(par2,1), p)
                     
                     if (test == "SW"){
                       result <- shapiro.test(sample)$p.value
                     } else if (test == "JB"){
                       result <- jarque.bera.test(sample)$p.value
                     }   
                     result
                   })
                   mean(p_vector < alpha)
                 })

data4 <- bind_cols(data3, Moc = powers)

  ggplot(data4,aes(x = Zmiana, y = Moc, color = Test)) +
  labs(title = "Zmiena mocy w zależności od par_2[1]", x = "Wartosc par2[1]", y = "Moc") +
  geom_smooth() + 
  facet_wrap(~ Dlugosc, nrow = 3)
```

```{r, echo=FALSE, message=FALSE}
set.seed(20)
powers <- sapply(1:nrow(data3),
                 function(i){
                   n <- data3[i, 1]
                   par2 <- data3[i, 3]  
                   test <- data3[i, 4]
                   
                   p_vector <- sapply(rep(n, N), function(x){
                     sample <- rmix(n, "norm", par1, "norm", c(1,par2), p)
                     
                     if (test == "SW"){
                       result <- shapiro.test(sample)$p.value
                     } else if (test == "JB"){
                       result <- jarque.bera.test(sample)$p.value
                     }   
                     result
                   })
                   mean(p_vector < alpha)
                 })

data4 <- bind_cols(data3, Moc = powers)


  ggplot(data4,aes(x = Zmiana, y = Moc, color = Test)) +
  labs(title = "Zmiena mocy w zależności od par_2[2]", x = "Wartosc par2[2]", y = "Moc") +
  geom_smooth() + 
  facet_wrap(~ Dlugosc, nrow = 3)
```

Grafiki pokazują, że moc testów zachowuje się prawie identycznie jak w momencie zmiany parametrów pierwszego rozkładu - gdy wartość parametrów zbliża się do wartości z rozkładu pierwszego moc maleje.  

***

### Zadanie 3  
